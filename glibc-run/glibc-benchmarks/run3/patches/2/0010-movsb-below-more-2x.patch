From 1b5b604d537e6ac5925989bf82e72218bb60df73 Mon Sep 17 00:00:00 2001
From: Noah Goldstein <goldstein.w.n@gmail.com>
Date: Sun, 22 Aug 2021 20:13:43 -0400
Subject: [PATCH 10/11] movsb below more 2x

---
 .../multiarch/memmove-vec-unaligned-erms.S    | 57 ++++++++++++-------
 1 file changed, 36 insertions(+), 21 deletions(-)

diff --git a/sysdeps/x86_64/multiarch/memmove-vec-unaligned-erms.S b/sysdeps/x86_64/multiarch/memmove-vec-unaligned-erms.S
index 8656e0fd96..614486bcef 100644
--- a/sysdeps/x86_64/multiarch/memmove-vec-unaligned-erms.S
+++ b/sysdeps/x86_64/multiarch/memmove-vec-unaligned-erms.S
@@ -406,25 +406,6 @@ L(copy_8_15):
 	ret
 #endif
 
-#if defined USE_MULTIARCH && IS_IN (libc)
-L(movsb):
-	movq	%rdi, %rcx
-	subq	%rsi, %rcx
-	cmpq	%rdx, %rcx
-	jb	L(more_8x_vec_backward_check_nop)
-	cmp	__x86_rep_movsb_stop_threshold(%rip), %RDX_LP
-# if AVOID_SHORT_DISTANCE_REP_MOVSB
-	andl	$X86_STRING_CONTROL_AVOID_SHORT_DISTANCE_REP_MOVSB, __x86_string_control(%rip)
-	jz	L(skip_short_movsb_check)
-	cmpl	$-64, %ecx
-	jae	L(more_8x_vec_forward)
-L(skip_short_movsb_check):
-# endif
-	mov	%RDX_LP, %RCX_LP
-	rep	movsb
-	ret
-	.p2align 4
-#endif
 
 
 #if defined USE_MULTIARCH && IS_IN (libc)
@@ -468,9 +449,34 @@ L(last_4x_vec):
 	VMOVU	%VEC(1), VEC_SIZE(%rdi)
 	VMOVU	%VEC(2), -VEC_SIZE(%rdi, %rdx)
 	VMOVU	%VEC(3), -(VEC_SIZE * 2)(%rdi, %rdx)
+#if !defined USE_MULTIARCH || !IS_IN (libc)
 L(nop):
+#endif
 	VZEROUPPER_RETURN
-	.p2align 4,,10
+
+#if defined USE_MULTIARCH && IS_IN (libc)
+	.p2align 4
+L(movsb):
+	movq	%rdi, %rcx
+	subq	%rsi, %rcx
+	cmpq	%rdx, %rcx
+	jb	L(more_8x_vec_backward_check_nop)
+	cmp	__x86_rep_movsb_stop_threshold(%rip), %RDX_LP
+	jae	L(more_8x_vec)
+# if AVOID_SHORT_DISTANCE_REP_MOVSB
+	andl	$X86_STRING_CONTROL_AVOID_SHORT_DISTANCE_REP_MOVSB, __x86_string_control(%rip)
+	jz	L(skip_short_movsb_check)
+	cmpl	$-64, %ecx
+	jae	L(more_8x_vec_forward)
+L(skip_short_movsb_check):
+# endif
+	mov	%RDX_LP, %RCX_LP
+	rep	movsb
+L(nop):
+	ret
+#endif
+
+	.p2align 4,, 10
 L(more_8x_vec):
 	/* Check if non-temporal move candidate.  */
 #if (defined USE_MULTIARCH || VEC_SIZE == 16) && IS_IN (libc)
@@ -543,7 +549,7 @@ L(more_8x_vec_backward):
 	leaq	(VEC_SIZE * -4 + -1)(%rdi, %rdx), %rdi
 	andq	$-(VEC_SIZE), %rdi
 	addq	%rdi, %rsi
-	.p2align 4,,11
+	.p2align 4,, 11
 L(loop_4x_vec_backward):
 	VMOVU	(VEC_SIZE * 3)(%rsi), %VEC(0)
 	VMOVU	(VEC_SIZE * 2)(%rsi), %VEC(1)
@@ -569,9 +575,18 @@ L(loop_4x_vec_backward):
 	VMOVU	%VEC(8), -VEC_SIZE(%rdx, %rcx)
 	VZEROUPPER_RETURN
 
+
+
 #if (defined USE_MULTIARCH || VEC_SIZE == 16) && IS_IN (libc)
 	.p2align 4
+L(large_memcpy_2x_check):
+# if (defined USE_MULTIARCH || VEC_SIZE == 16) && IS_IN (libc)
+	/* Check non-temporal store threshold.  */
+	cmp	__x86_shared_non_temporal_threshold(%rip), %RDX_LP
+	jb	L(more_8x_vec_check)
+# endif
 L(large_memcpy_2x):
+
 	/* Compute absolute value of difference between source and destination.
 	 */
 	movq	%rdi, %r9
-- 
2.25.1

