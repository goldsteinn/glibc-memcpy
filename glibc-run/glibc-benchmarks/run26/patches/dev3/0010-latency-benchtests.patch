From f8dbf3b461aac10f81c6a5b5bc044095728eade7 Mon Sep 17 00:00:00 2001
From: Noah Goldstein <goldstein.w.n@gmail.com>
Date: Sun, 5 Sep 2021 19:22:43 -0500
Subject: [PATCH 10/10] latency benchtests

---
 benchtests/bench-memcpy-random.c              | 16 +++++-
 benchtests/bench-memcpy.c                     |  6 ++-
 benchtests/bench-memmove-walk.c               |  2 +
 benchtests/bench-memmove.c                    |  6 ++-
 .../multiarch/memmove-vec-unaligned-erms.S    | 49 +++++++++----------
 5 files changed, 46 insertions(+), 33 deletions(-)

diff --git a/benchtests/bench-memcpy-random.c b/benchtests/bench-memcpy-random.c
index bf926adc86..aca74c750f 100644
--- a/benchtests/bench-memcpy-random.c
+++ b/benchtests/bench-memcpy-random.c
@@ -23,7 +23,7 @@
 #include "bench-string.h"
 #include <assert.h>
 #include "json-lib.h"
-
+#define LFENCE asm volatile("lfence" : : :);
 #define MAX_COPIES 8192
 
 IMPL (memcpy, 1)
@@ -134,10 +134,17 @@ do_one_test (json_ctx_t *json_ctx, impl_t *impl, char *dst, char *src,
   for (int j = 0; j < n; j++)
     CALL (impl, dst + copy[j].dst, src + copy[j].src, copy[j].len);
 
+  LFENCE;
   TIMING_NOW (start);
   for (int i = 0; i < iters; ++i)
+  {
     for (int j = 0; j < n; j++)
+    {
       CALL (impl, dst + copy[j].dst, src + copy[j].src, copy[j].len);
+      LFENCE;
+    }
+  }
+  LFENCE;
   TIMING_NOW (stop);
 
   TIMING_DIFF (cur, start, stop);
@@ -154,11 +161,16 @@ do_one_fixed_test (json_ctx_t *json_ctx, impl_t *impl, char *dst, char *src,
 
   for (int j = 0; j < n; j++)
     CALL (impl, dst + copy[j].dst, src + copy[j].src, size);
-
+  LFENCE;
   TIMING_NOW (start);
   for (int i = 0; i < iters; ++i)
+  {
     for (int j = 0; j < n; j++)
+    {
       CALL (impl, dst + copy[j].dst, src + copy[j].src, size);
+      LFENCE;
+    }
+  }
   TIMING_NOW (stop);
 
   TIMING_DIFF (cur, start, stop);
diff --git a/benchtests/bench-memcpy.c b/benchtests/bench-memcpy.c
index 9b33a2179d..a8395b813a 100644
--- a/benchtests/bench-memcpy.c
+++ b/benchtests/bench-memcpy.c
@@ -15,7 +15,7 @@
    You should have received a copy of the GNU Lesser General Public
    License along with the GNU C Library; if not, see
    <https://www.gnu.org/licenses/>.  */
-
+#define LFENCE asm volatile("lfence" : : :);
 #ifndef MEMCPY_RESULT
 # define MEMCPY_RESULT(dst, len) dst
 # define MIN_PAGE_SIZE 131072
@@ -44,13 +44,15 @@ do_one_test (json_ctx_t *json_ctx, impl_t *impl, char *dst, const char *src,
     {
       CALL (impl, dst, src, len);
     }
+  LFENCE;
   TIMING_NOW (start);
   for (i = 0; i < iters; ++i)
     {
       CALL (impl, dst, src, len);
+      LFENCE;
     }
   TIMING_NOW (stop);
-
+  LFENCE;
   TIMING_DIFF (cur, start, stop);
 
   json_element_double (json_ctx, (double) cur / (double) iters);
diff --git a/benchtests/bench-memmove-walk.c b/benchtests/bench-memmove-walk.c
index 18b716f5cb..723e336a9e 100644
--- a/benchtests/bench-memmove-walk.c
+++ b/benchtests/bench-memmove-walk.c
@@ -60,7 +60,9 @@ do_one_test (json_ctx_t *json_ctx, impl_t *impl, char *dst, char *src,
   TIMING_NOW (start);
   /* Copy the entire buffer backwards, LEN at a time.  */
   for (; src_end >= src && dst <= dst_end; dst += len, src_end -= len, i++)
+  {
     CALL (impl, dst, src_end, len);
+  }
   TIMING_NOW (stop);
 
   TIMING_DIFF (cur, start, stop);
diff --git a/benchtests/bench-memmove.c b/benchtests/bench-memmove.c
index 855f4d0649..eec349fcea 100644
--- a/benchtests/bench-memmove.c
+++ b/benchtests/bench-memmove.c
@@ -15,7 +15,7 @@
    You should have received a copy of the GNU Lesser General Public
    License along with the GNU C Library; if not, see
    <https://www.gnu.org/licenses/>.  */
-
+#define LFENCE asm volatile("lfence" : : :);
 #define TEST_MAIN
 #define TEST_NAME "memmove"
 #include "bench-string.h"
@@ -38,13 +38,15 @@ do_one_test (json_ctx_t *json_ctx, impl_t *impl, char *dst, char *src,
     {
       CALL (impl, dst, src, len);
     }
+  LFENCE;
   TIMING_NOW (start);
   for (i = 0; i < iters; ++i)
     {
       CALL (impl, dst, src, len);
+      LFENCE;
     }
   TIMING_NOW (stop);
-
+  LFENCE;
   TIMING_DIFF (cur, start, stop);
 
   json_element_double (json_ctx, (double) cur / (double) iters);
diff --git a/sysdeps/x86_64/multiarch/memmove-vec-unaligned-erms.S b/sysdeps/x86_64/multiarch/memmove-vec-unaligned-erms.S
index 3b9f9459a3..3e51015555 100644
--- a/sysdeps/x86_64/multiarch/memmove-vec-unaligned-erms.S
+++ b/sysdeps/x86_64/multiarch/memmove-vec-unaligned-erms.S
@@ -476,7 +476,7 @@ L(movsb):
 	/* Save dest for storing aligning VECs later.  */
 	movq	%rdi, %r8
 # endif
-	/* If above x86_rep_movsb_stop_threshold most likely is candidate
+	/* If above __x86_rep_movsb_stop_threshold most likely is candidate
 	   for NT moves aswell.  */
 	cmp	__x86_rep_movsb_stop_threshold(%rip), %RDX_LP
 	jae	L(large_memcpy_2x_check)
@@ -565,10 +565,7 @@ L(more_2x_vec):
 	VMOVU	%VEC(6), -(VEC_SIZE * 3)(%rdi, %rdx)
 	VMOVU	%VEC(7), -(VEC_SIZE * 4)(%rdi, %rdx)
 	VZEROUPPER_RETURN
-	/* Align if doesn't cost too much code size. 6 bytes so that after
-	   jump to target a full mov instruction will always be able to be
-	   fetched.  */
-	.p2align 4,, 6
+	.p2align 4
 L(last_4x_vec):
 	/* Copy from 2 * VEC + 1 to 4 * VEC, inclusively.  */
 	VMOVU	-VEC_SIZE(%rsi, %rdx), %VEC(2)
@@ -610,12 +607,11 @@ L(more_8x_vec):
 	/* Isolate just sign bit of r8.  */
 	shrq	$63, %r8
 	/* Get 4k difference dst - src.  */
-	andl	$(PAGE_SIZE - 256), %ecx
-	/* If r8 is non-zero must do foward for correctness. Otherwise if
+	andl	$(PAGE_SIZE - 2048), %ecx
+	/* If r8 is non-zero musyt do foward for correctness. Otherwise if
 	   ecx is non-zero there is 4k False Alaising so do backward copy.  */
 	addl	%r8d, %ecx
 	jz	L(more_8x_vec_backward)
-
 	/* Entry if rdx is greater than __x86_rep_movsb_stop_threshold but
 	   less than __x86_shared_non_temporal_threshold, if rdx is greater
 	   than __x86_shared_non_temporal_threshold but there is overlap, or
@@ -623,28 +619,27 @@ L(more_8x_vec):
 L(more_8x_vec_forward):
 	/* Load first and last 4 * VEC to support overlapping addresses.  */
 	VMOVU	(%rsi), %VEC(4)
-	VMOVU	-VEC_SIZE(%rsi, %rdx), %VEC(5)
-	VMOVU	-(VEC_SIZE * 2)(%rsi, %rdx), %VEC(6)
+	leaq	(VEC_SIZE * -4)(%rsi, %rdx), %r8
+	VMOVU	(%r8), %VEC(5)
+	VMOVU	VEC_SIZE(%r8), %VEC(6)
+	VMOVU	(VEC_SIZE * 2)(%r8), %VEC(7)
+	VMOVU	(VEC_SIZE * 3)(%r8), %VEC(8)
+	/* Align dst.  */
 	/* Save begining of dst.  */
 	movq	%rdi, %rcx
 	/* Align dst to VEC_SIZE - 1.  */
 	orq	$(VEC_SIZE - 1), %rdi
-	VMOVU	-(VEC_SIZE * 3)(%rsi, %rdx), %VEC(7)
-	VMOVU	-(VEC_SIZE * 4)(%rsi, %rdx), %VEC(8)
-
-	/* Align dst.  */
-
 	/* Subtract dst from src. Add back after dst aligned.  */
 	subq	%rcx, %rsi
-	/* Restore src adjusted with new value for aligned dst.  */
-	leaq	1(%rdi, %rsi), %rsi
 	/* Finish aligning dst.  */
 	incq	%rdi
-	/* Store end of buffer minus tail in rdx.  */
-	leaq	(VEC_SIZE * -4)(%rcx, %rdx), %rdx
+	/* Restore src adjusted with new value for aligned dst.  */
+	addq	%rdi, %rsi
+	/* Store end of buffer in rdx.  */
+	addq	%rcx, %rdx
 
 	/* Dont use multi-byte nop to align.  */
-	.p2align 4,, 10
+	.p2align 4,, 11
 L(loop_4x_vec_forward):
 	/* Copy 4 * VEC a time forward.  */
 	VMOVU	(%rsi), %VEC(0)
@@ -657,20 +652,21 @@ L(loop_4x_vec_forward):
 	VMOVA	%VEC(2), (VEC_SIZE * 2)(%rdi)
 	VMOVA	%VEC(3), (VEC_SIZE * 3)(%rdi)
 	subq	$-(VEC_SIZE * 4), %rdi
-	cmpq	%rdi, %rdx
+	cmpq	%rsi, %r8
 	ja	L(loop_4x_vec_forward)
+
 	/* Store the last 4 * VEC.  */
-	VMOVU	%VEC(5), (VEC_SIZE * 3)(%rdx)
-	VMOVU	%VEC(6), (VEC_SIZE * 2)(%rdx)
-	VMOVU	%VEC(7), VEC_SIZE(%rdx)
-	VMOVU	%VEC(8), (%rdx)
+	VMOVU	%VEC(5), (VEC_SIZE * -4)(%rdx)
+	VMOVU	%VEC(6), (VEC_SIZE * -3)(%rdx)
+	VMOVU	%VEC(7), (VEC_SIZE * -2)(%rdx)
+	VMOVU	%VEC(8), (VEC_SIZE * -1)(%rdx)
 	/* Store the first VEC.  */
 	VMOVU	%VEC(4), (%rcx)
 	/* Keep L(nop_backward) target close to jmp for 2-byte encoding.  */
 L(nop_backward):
 	VZEROUPPER_RETURN
 
-	.p2align 4,, 10
+	.p2align 4,, 9
 L(more_8x_vec_backward_check_nop):
 	testq	%rcx, %rcx
 	jz	L(nop_backward)
@@ -690,7 +686,6 @@ L(more_8x_vec_backward):
 	andq	$-(VEC_SIZE), %rcx
 	/* Restore src.  */
 	addq	%rcx, %rsi
-
 	/* Don't use multi-byte nop to align.  */
 	.p2align 4,, 11
 L(loop_4x_vec_backward):
-- 
2.25.1

